{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "# tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "# model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def evaluate_sent_level(predicted_string, alignment_string):\n",
    "    # # Example usage\n",
    "    # alignment_string = \"5-6 3-4 25p22 5-7 2p3 25p21 4-5 11-14 12-13 13-15 27p20 9-11 25p23 8-8 22-25 20-27 17-18 1-1 28-28 26p20 18-19 6p9 1-2 7-10 10-12 21-24 15-17 14-16 23-26\"\n",
    "    # predicted_string = \"5-6 3-4 25-22 ...\"  # Replace with your model's predicted alignments\n",
    "\n",
    "    def parse_alignments(alignment_string):\n",
    "        sure_alignments = set()\n",
    "        possible_alignments = set()\n",
    "\n",
    "        # Split the string into individual alignments\n",
    "        alignments = alignment_string.split()\n",
    "\n",
    "        for alignment in alignments:\n",
    "            if 'p' in alignment:\n",
    "                # Possible alignment\n",
    "                aligned_words = tuple(map(int, alignment.split('p')))\n",
    "                possible_alignments.add(aligned_words)\n",
    "            else:\n",
    "                # Sure alignment\n",
    "                aligned_words = tuple(map(int, alignment.split('-')))\n",
    "                sure_alignments.add(aligned_words)\n",
    "        return sure_alignments, possible_alignments\n",
    "\n",
    "    def calculate_f1(predicted_alignments, sure_alignments, possible_alignments):\n",
    "        a_and_s = len(predicted_alignments.intersection(sure_alignments))\n",
    "        a_and_p = len(predicted_alignments.intersection(possible_alignments))\n",
    "        prec = a_and_p / len(predicted_alignments) if len(predicted_alignments) > 0 else 0\n",
    "        rec = a_and_s / len(sure_alignments) if len(sure_alignments) > 0 else 0\n",
    "\n",
    "        if prec + rec == 0:\n",
    "            return 0\n",
    "        return 2 * (prec * rec) / (prec + rec), prec, rec\n",
    "\n",
    "    def calculate_aer(predicted_alignments, sure_alignments, possible_alignments):\n",
    "        a_and_s = len(predicted_alignments.intersection(sure_alignments))\n",
    "        a_and_p = len(predicted_alignments.intersection(possible_alignments))\n",
    "        return 1 - (a_and_s + a_and_p) / (len(predicted_alignments) + len(sure_alignments))\n",
    "\n",
    "    \n",
    "    # Parse alignments\n",
    "    sure_alignments, possible_alignments = parse_alignments(alignment_string)\n",
    "    predicted_alignments = parse_alignments(predicted_string)[0]  # Assuming model predicts only sure alignments\n",
    "\n",
    "    # Calculate metrics\n",
    "    f1_score, prec, rec = calculate_f1(predicted_alignments, sure_alignments, possible_alignments.union(sure_alignments))\n",
    "    aer = calculate_aer(predicted_alignments, sure_alignments, possible_alignments.union(sure_alignments))\n",
    "\n",
    "    # print(\"F1 Score:\", f1_score)\n",
    "    # print(\"AER:\", aer)\n",
    "    return {\"F1 Score\": f1_score, \"AER\": aer, \"Precision\": prec, \"Recall\": rec}\n",
    "\n",
    "def evaluate_corpus_level(pred_list, align_list):\n",
    "    # # Example usage\n",
    "    # alignment_string = \"5-6 3-4 25p22 5-7 2p3 25p21 4-5 11-14 12-13 13-15 27p20 9-11 25p23 8-8 22-25 20-27 17-18 1-1 28-28 26p20 18-19 6p9 1-2 7-10 10-12 21-24 15-17 14-16 23-26\"\n",
    "    # predicted_string = \"5-6 3-4 25-22 ...\"  # Replace with your model's predicted alignments\n",
    "\n",
    "    def parse_alignments(alignment_string):\n",
    "        sure_alignments = set()\n",
    "        possible_alignments = set()\n",
    "\n",
    "        # Split the string into individual alignments\n",
    "        alignments = alignment_string.split()\n",
    "\n",
    "        for alignment in alignments:\n",
    "            if 'p' in alignment:\n",
    "                # Possible alignment\n",
    "                aligned_words = tuple(map(int, alignment.split('p')))\n",
    "                possible_alignments.add(aligned_words)\n",
    "            else:\n",
    "                # Sure alignment\n",
    "                aligned_words = tuple(map(int, alignment.split('-')))\n",
    "                sure_alignments.add(aligned_words)\n",
    "\n",
    "        return sure_alignments, possible_alignments\n",
    "\n",
    "    def compare(predicted_alignments, sure_alignments, possible_alignments):\n",
    "        a_and_s = len(predicted_alignments.intersection(sure_alignments))\n",
    "        a_and_p = len(predicted_alignments.intersection(possible_alignments))\n",
    "        \n",
    "        return a_and_p, a_and_s\n",
    "\n",
    "    def calculate_aer(predicted_alignments, sure_alignments, possible_alignments):\n",
    "        a_and_s = len(predicted_alignments.intersection(sure_alignments))\n",
    "        a_and_p = len(predicted_alignments.intersection(possible_alignments))\n",
    "        return 1 - (a_and_s + a_and_p) / (len(predicted_alignments) + len(sure_alignments))\n",
    "\n",
    "    sum_a_and_s = 0\n",
    "    sum_a_and_p = 0\n",
    "    sum_len_a = 0\n",
    "    sum_len_s = 0\n",
    "    \n",
    "    for pred, align in zip(pred_list, align_list):\n",
    "        # Parse alignments\n",
    "        sure_alignments, possible_alignments = parse_alignments(align)\n",
    "        predicted_alignments = parse_alignments(pred)[0]\n",
    "        possible_alignments = possible_alignments.union(sure_alignments)\n",
    "        \n",
    "        a_and_p, a_and_s = compare(predicted_alignments, sure_alignments, possible_alignments)\n",
    "        sum_a_and_s += a_and_s\n",
    "        sum_a_and_p += a_and_p\n",
    "        sum_len_a += len(predicted_alignments)\n",
    "        sum_len_s += len(sure_alignments)\n",
    "    \n",
    "    precision = sum_a_and_p / sum_len_a\n",
    "    recall = sum_a_and_s / sum_len_s\n",
    "    aer = 1 - (sum_a_and_s + sum_a_and_p) / (sum_len_a + sum_len_s)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return {\"F1 Score\": f1_score, \"AER\": aer, \"Precision\": precision, \"Recall\": recall}\n",
    "\n",
    "\n",
    "def format_alignments(alignments):\n",
    "        \"\"\"\n",
    "        Formats the set of alignment tuples into a string where each alignment is represented\n",
    "        by 'source-target' and source/target indices are one-based.\n",
    "        \"\"\"\n",
    "        formatted = ' '.join(f'{src+1}-{tgt+1}' for src, tgt in sorted(alignments))\n",
    "        return formatted\n",
    "    \n",
    "def grow_diag_final_balanced(forward_alignments, reverse_alignments, src_len, tgt_len):\n",
    "    \"\"\"\n",
    "    A more balanced implementation of Grow-diag-final heuristic.\n",
    "    \"\"\"\n",
    "    def get_neighbors(src, tgt):\n",
    "        \"\"\"Generate direct neighbors for a given source-target position.\"\"\"\n",
    "        neighbors = []\n",
    "        for d_src in [-1, 0, 1]:\n",
    "            for d_tgt in [-1, 0, 1]:\n",
    "                if d_src == 0 and d_tgt == 0:\n",
    "                    continue  # Skip the position itself\n",
    "                n_src, n_tgt = src + d_src, tgt + d_tgt\n",
    "                if 0 <= n_src < src_len and 0 <= n_tgt < tgt_len:\n",
    "                    neighbors.append((n_src, n_tgt))\n",
    "        return neighbors\n",
    "\n",
    "    # Step 1: Intersection as the starting point\n",
    "    combined_alignments = forward_alignments & reverse_alignments\n",
    "\n",
    "    # Step 2: Grow - selectively\n",
    "    unaligned_src = set(range(src_len))\n",
    "    unaligned_tgt = set(range(tgt_len))\n",
    "    for (src, tgt) in combined_alignments:\n",
    "        unaligned_src.discard(src)\n",
    "        unaligned_tgt.discard(tgt)\n",
    "\n",
    "    def is_neighbor_aligned(src, tgt):\n",
    "        for neighbor in get_neighbors(src, tgt):\n",
    "            if neighbor in combined_alignments:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    added = True\n",
    "    while added:\n",
    "        added = False\n",
    "        new_points = set()\n",
    "        for src in unaligned_src:\n",
    "            for tgt in unaligned_tgt:\n",
    "                if ((src, tgt) in forward_alignments or (src, tgt) in reverse_alignments) and is_neighbor_aligned(src, tgt):\n",
    "                    new_points.add((src, tgt))\n",
    "                    added = True\n",
    "\n",
    "        for point in new_points:\n",
    "            combined_alignments.add(point)\n",
    "            unaligned_src.discard(point[0])\n",
    "            unaligned_tgt.discard(point[1])\n",
    "\n",
    "    # Step 3: Final - cautiously add unique alignments without causing conflicts\n",
    "    for src in range(src_len):\n",
    "        for tgt in range(tgt_len):\n",
    "            if (src, tgt) in forward_alignments ^ reverse_alignments and not is_neighbor_aligned(src, tgt):\n",
    "                combined_alignments.add((src, tgt))\n",
    "\n",
    "    return format_alignments(combined_alignments)\n",
    "\n",
    "def grow_diag_final_and(forward_alignments, reverse_alignments, src_len, tgt_len):\n",
    "    \"\"\"\n",
    "    Implements the Grow-diag-final-and heuristic for combining forward and reverse alignments.\n",
    "    This variant is more conservative, focusing on high-precision alignments.\n",
    "    \"\"\"\n",
    "    def get_neighbors(src, tgt):\n",
    "        \"\"\"Generate neighboring positions for a given source-target position.\"\"\"\n",
    "        neighbors = []\n",
    "        for d_src in [-1, 0, 1]:\n",
    "            for d_tgt in [-1, 0, 1]:\n",
    "                if d_src == 0 and d_tgt == 0:\n",
    "                    continue  # Skip the position itself\n",
    "                n_src, n_tgt = src + d_src, tgt + d_tgt\n",
    "                if 0 <= n_src < src_len and 0 <= n_tgt < tgt_len:\n",
    "                    neighbors.append((n_src, n_tgt))\n",
    "        return neighbors\n",
    "\n",
    "    # Start with the strict intersection of forward and reverse alignments\n",
    "    combined_alignments = forward_alignments & reverse_alignments\n",
    "\n",
    "    # Initialize unaligned sets for source and target\n",
    "    unaligned_src = {i for i in range(src_len)} - {src for src, _ in combined_alignments}\n",
    "    unaligned_tgt = {i for i in range(tgt_len)} - {tgt for _, tgt in combined_alignments}\n",
    "\n",
    "    added = True\n",
    "    while added:\n",
    "        added = False\n",
    "        new_points = set()\n",
    "        for src in unaligned_src:\n",
    "            for tgt in unaligned_tgt:\n",
    "                if (src, tgt) in forward_alignments and (src, tgt) in reverse_alignments:\n",
    "                    neighbors = get_neighbors(src, tgt)\n",
    "                    if any((n_src, n_tgt) in combined_alignments for n_src, n_tgt in neighbors):\n",
    "                        new_points.add((src, tgt))\n",
    "                        added = True\n",
    "\n",
    "        for point in new_points:\n",
    "            combined_alignments.add(point)\n",
    "            unaligned_src.discard(point[0])\n",
    "            unaligned_tgt.discard(point[1])\n",
    "\n",
    "    return format_alignments(combined_alignments)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming x and y are your data tensors\n",
    "# x: tensor of shape [m, dim]\n",
    "# y: tensor of shape [n, dim]\n",
    "def find_avg_vector2(x, y):\n",
    "    x = x.detach()\n",
    "    y = y.detach()\n",
    "    \n",
    "    def compute_l2_distance(tensor_a, tensor_b):\n",
    "        return torch.norm(tensor_a - tensor_b, dim=1)\n",
    "\n",
    "    def compute_pair_wise_l2_distance(tensor_a, tensor_b):\n",
    "        return torch.norm(tensor_a.unsqueeze(1) - tensor_b.unsqueeze(0), dim=2)\n",
    "    \n",
    "    def objective_initialization(c, x, y, alpha):\n",
    "        combined_x_y = torch.cat([x, y], dim=0)\n",
    "        xy_distances = compute_pair_wise_l2_distance(x, y)\n",
    "        c_to_xy_distances = compute_l2_distance(combined_x_y, c)\n",
    "        distance_diff = (xy_distances.view(-1).unsqueeze(1) - c_to_xy_distances.unsqueeze(0)).reshape(-1).abs().mean()\n",
    "        return alpha * c_to_xy_distances.mean() + (1 - alpha) * distance_diff\n",
    "\n",
    "    def variance_objective(c, x, y, lambda_weight):\n",
    "        combined_x_y = torch.cat([x, y], dim=0)\n",
    "        xy_distances = compute_pair_wise_l2_distance(x, y)\n",
    "        c_to_xy_distances = compute_l2_distance(combined_x_y, c)\n",
    "        var_c_to_xy = torch.var(c_to_xy_distances)\n",
    "        var_diff = (xy_distances.view(-1).unsqueeze(1) - c_to_xy_distances.unsqueeze(0)).reshape(-1).var()\n",
    "        return lambda_weight * var_c_to_xy + (1 - lambda_weight) * var_diff\n",
    "\n",
    "    # Parameters\n",
    "    alpha = 0.5\n",
    "    lambda_weight = 0.5\n",
    "    learning_rate = 0.01\n",
    "    max_iterations = 200\n",
    "    convergence_threshold = 1e-6\n",
    "\n",
    "    # Initialize c\n",
    "    c = torch.mean(torch.cat([x.detach(), y.detach()], dim=0), dim=0).requires_grad_(True).to(x)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam([c], lr=learning_rate)\n",
    "\n",
    "    # Iterative Process\n",
    "    previous_loss_all = float('inf')\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        # Step 1: Initialization Loop\n",
    "        previous_loss_median = float('inf')\n",
    "        for _idx in range(max_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            loss_init = objective_initialization(c, x, y, alpha)\n",
    "            loss_init.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Early Stopping for Step 1\n",
    "            if torch.abs(previous_loss_median - loss_init) < convergence_threshold:\n",
    "                break\n",
    "            previous_loss_median = loss_init\n",
    "\n",
    "        # Step 2: Variance Minimization Loop\n",
    "        previous_loss_var = float('inf')\n",
    "        for _idx in range(max_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            loss_variance = variance_objective(c, x, y, lambda_weight)\n",
    "            loss_variance.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Early Stopping for Step 2\n",
    "            if torch.abs(previous_loss_var - loss_variance) < convergence_threshold:\n",
    "                break\n",
    "            previous_loss_var = loss_variance\n",
    "\n",
    "        # Convergence Check for Overall Process\n",
    "        if torch.abs(loss_variance - previous_loss_all) < convergence_threshold:\n",
    "            # print(f\"Converged in {iteration+1} overall iterations\")\n",
    "            break\n",
    "        previous_loss_all = loss_variance\n",
    "    # print(iteration)\n",
    "    return c\n",
    "\n",
    "def find_avg_vector_xy(x, y):\n",
    "    x = x.detach()\n",
    "    y = y.detach()\n",
    "    \n",
    "    def compute_l2_distance(tensor_a, tensor_b):\n",
    "        return torch.norm(tensor_a - tensor_b, dim=1)\n",
    "\n",
    "    def compute_pair_wise_l2_distance(tensor_a, tensor_b):\n",
    "        return torch.norm(tensor_a.unsqueeze(1) - tensor_b.unsqueeze(0), dim=2)\n",
    "    \n",
    "    def objective_initialization(c, x, y, alpha):\n",
    "        combined_x_y = torch.cat([x, y], dim=0)\n",
    "        xy_distances = compute_pair_wise_l2_distance(combined_x_y, combined_x_y)\n",
    "        mask = torch.ones_like(xy_distances, dtype=torch.bool)\n",
    "        mask.fill_diagonal_(0)\n",
    "        xy_distances = xy_distances[mask].reshape(-1)\n",
    "        c_to_xy_distances = compute_l2_distance(combined_x_y, c)\n",
    "        distance_diff = (xy_distances.unsqueeze(1) - c_to_xy_distances.unsqueeze(0)).reshape(-1).abs().mean()\n",
    "        return alpha * c_to_xy_distances.mean() + (1 - alpha) * distance_diff\n",
    "\n",
    "    def variance_objective(c, x, y, lambda_weight):\n",
    "        combined_x_y = torch.cat([x, y], dim=0)\n",
    "        xy_distances = compute_pair_wise_l2_distance(combined_x_y, combined_x_y)\n",
    "        mask = torch.ones_like(xy_distances, dtype=torch.bool)\n",
    "        mask.fill_diagonal_(0)\n",
    "        xy_distances = xy_distances[mask].reshape(-1)\n",
    "        \n",
    "        c_to_xy_distances = compute_l2_distance(combined_x_y, c)\n",
    "        var_c_to_xy = torch.var(c_to_xy_distances)\n",
    "        var_diff = (xy_distances.unsqueeze(1) - c_to_xy_distances.unsqueeze(0)).reshape(-1).var()\n",
    "        return lambda_weight * var_c_to_xy + (1 - lambda_weight) * var_diff\n",
    "\n",
    "    # Parameters\n",
    "    alpha = 0.5\n",
    "    lambda_weight = 0.5\n",
    "    learning_rate = 0.01\n",
    "    max_iterations = 200\n",
    "    convergence_threshold = 1e-6\n",
    "\n",
    "    # Initialize c\n",
    "    c = torch.mean(torch.cat([x.detach(), y.detach()], dim=0), dim=0).requires_grad_(True).to(x)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam([c], lr=learning_rate)\n",
    "\n",
    "    # Iterative Process\n",
    "    previous_loss_all = float('inf')\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        # Step 1: Initialization Loop\n",
    "        previous_loss_median = float('inf')\n",
    "        for _idx in range(max_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            loss_init = objective_initialization(c, x, y, alpha)\n",
    "            loss_init.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Early Stopping for Step 1\n",
    "            if torch.abs(previous_loss_median - loss_init) < convergence_threshold:\n",
    "                break\n",
    "            previous_loss_median = loss_init\n",
    "\n",
    "        # Step 2: Variance Minimization Loop\n",
    "        previous_loss_var = float('inf')\n",
    "        for _idx in range(max_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            loss_variance = variance_objective(c, x, y, lambda_weight)\n",
    "            loss_variance.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Early Stopping for Step 2\n",
    "            if torch.abs(previous_loss_var - loss_variance) < convergence_threshold:\n",
    "                break\n",
    "            previous_loss_var = loss_variance\n",
    "\n",
    "        # Convergence Check for Overall Process\n",
    "        if torch.abs(loss_variance - previous_loss_all) < convergence_threshold:\n",
    "            # print(f\"Converged in {iteration+1} overall iterations\")\n",
    "            break\n",
    "        previous_loss_all = loss_variance\n",
    "    # print(iteration)\n",
    "    return c\n",
    "\n",
    "\n",
    "def find_avg_vector_x(x, y):\n",
    "    # only  src (x)\n",
    "    x = x.detach()\n",
    "    y = y.detach()\n",
    "    \n",
    "    def compute_l2_distance(tensor_a, tensor_b):\n",
    "        return torch.norm(tensor_a - tensor_b, dim=1)\n",
    "\n",
    "    def compute_pair_wise_l2_distance(tensor_a, tensor_b):\n",
    "        return torch.norm(tensor_a.unsqueeze(1) - tensor_b.unsqueeze(0), dim=2)\n",
    "    \n",
    "    def objective_initialization(c, x, y, alpha):\n",
    "        x_to_x_distances = compute_pair_wise_l2_distance(x, x) \n",
    "        mask = torch.ones_like(x_to_x_distances, dtype=torch.bool)\n",
    "        mask.fill_diagonal_(0)\n",
    "        x_to_x_distances = x_to_x_distances[mask].reshape(-1)\n",
    "        \n",
    "        c_to_x_distances = compute_l2_distance(x, c)\n",
    "        distance_diff = (x_to_x_distances.view(-1).unsqueeze(1) - c_to_x_distances.unsqueeze(0)).reshape(-1).abs().mean()\n",
    "        return alpha * c_to_x_distances.mean() + (1 - alpha) * distance_diff\n",
    "\n",
    "    def variance_objective(c, x, y, lambda_weight):\n",
    "        x_to_x_distances = compute_pair_wise_l2_distance(x, x) \n",
    "        mask = torch.ones_like(x_to_x_distances, dtype=torch.bool)\n",
    "        mask.fill_diagonal_(0)\n",
    "        x_to_x_distances = x_to_x_distances[mask].reshape(-1)\n",
    "        c_to_x_distances = compute_l2_distance(x, c)\n",
    "        var_c_to_x = torch.var(c_to_x_distances)\n",
    "        var_diff = (x_to_x_distances.view(-1).unsqueeze(1) - c_to_x_distances.unsqueeze(0)).reshape(-1).var()\n",
    "        return lambda_weight * var_c_to_x + (1 - lambda_weight) * var_diff\n",
    "\n",
    "    # Parameters\n",
    "    alpha = 0.5\n",
    "    lambda_weight = 0.5\n",
    "    learning_rate = 0.01\n",
    "    max_iterations = 200\n",
    "    convergence_threshold = 1e-6\n",
    "\n",
    "    # Initialize c\n",
    "    c = torch.mean(torch.cat([x.detach(), y.detach()], dim=0), dim=0).requires_grad_(True).to(x)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam([c], lr=learning_rate)\n",
    "\n",
    "    # Iterative Process\n",
    "    previous_loss_all = float('inf')\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        # Step 1: Initialization Loop\n",
    "        previous_loss_median = float('inf')\n",
    "        for _idx in range(max_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            loss_init = objective_initialization(c, x, y, alpha)\n",
    "            loss_init.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Early Stopping for Step 1\n",
    "            if torch.abs(previous_loss_median - loss_init) < convergence_threshold:\n",
    "                break\n",
    "            previous_loss_median = loss_init\n",
    "\n",
    "        # Step 2: Variance Minimization Loop\n",
    "        previous_loss_var = float('inf')\n",
    "        for _idx in range(max_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            loss_variance = variance_objective(c, x, y, lambda_weight)\n",
    "            loss_variance.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Early Stopping for Step 2\n",
    "            if torch.abs(previous_loss_var - loss_variance) < convergence_threshold:\n",
    "                break\n",
    "            previous_loss_var = loss_variance\n",
    "\n",
    "        # Convergence Check for Overall Process\n",
    "        if torch.abs(loss_variance - previous_loss_all) < convergence_threshold:\n",
    "            # print(f\"Converged in {iteration+1} overall iterations\")\n",
    "            break\n",
    "        previous_loss_all = loss_variance\n",
    "    # print(iteration)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 02:11:39.534690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Processing:   0%|          | 0/508 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1078, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\n",
      "Processing:   0%|          | 0/508 [26:05<?, ?it/s]  File \"_pydevd_bundle/pydevd_cython.pyx\", line 297, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
      "  File \"/home/chenyang/anaconda3/envs/pytorch2/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 1976, in do_wait_suspend\n",
      "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
      "  File \"/home/chenyang/anaconda3/envs/pytorch2/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2011, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 460\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror emb @\u001b[39m\u001b[38;5;124m'\u001b[39m, test_line_id)\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 460\u001b[0m predicted_alin_rev, P_rev, C_rev \u001b[38;5;241m=\u001b[39m \u001b[43mget_ot_align\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_emb_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_emb_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimple_avg_unk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml2r\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_fwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m predicted_alin_fwd, P_fwd, C_fwd \u001b[38;5;241m=\u001b[39m get_ot_align(tgt_emb_, src_emb_, simple_avg_unk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2r\u001b[39m\u001b[38;5;124m'\u001b[39m, thres\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, is_fwd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    464\u001b[0m pmi_align_str \u001b[38;5;241m=\u001b[39m pmi_align(src_emb_, tgt_emb_)\n",
      "Cell \u001b[0;32mIn[8], line 409\u001b[0m, in \u001b[0;36mget_ot_align\u001b[0;34m(src_rep, mt_rep, simple_avg_unk, method, thres, is_fwd)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;66;03m# avg_src_rep = find_avg_vector_xy(src_rep, mt_rep).detach()\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     avg_src_rep \u001b[38;5;241m=\u001b[39m avg_src_rep\u001b[38;5;241m.\u001b[39mto(mt_rep)\n\u001b[0;32m--> 409\u001b[0m     src_rep \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcat([src_rep, avg_src_rep\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    411\u001b[0m P, C \u001b[38;5;241m=\u001b[39m get_ot_map(src_rep, mt_rep)\n\u001b[1;32m    413\u001b[0m predicted_align \u001b[38;5;241m=\u001b[39m get_predicted_alignment(P, method\u001b[38;5;241m=\u001b[39mmethod, thres\u001b[38;5;241m=\u001b[39mthres, is_fwd\u001b[38;5;241m=\u001b[39mis_fwd)\n",
      "Cell \u001b[0;32mIn[8], line 409\u001b[0m, in \u001b[0;36mget_ot_align\u001b[0;34m(src_rep, mt_rep, simple_avg_unk, method, thres, is_fwd)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;66;03m# avg_src_rep = find_avg_vector_xy(src_rep, mt_rep).detach()\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     avg_src_rep \u001b[38;5;241m=\u001b[39m avg_src_rep\u001b[38;5;241m.\u001b[39mto(mt_rep)\n\u001b[0;32m--> 409\u001b[0m     src_rep \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcat([src_rep, avg_src_rep\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    411\u001b[0m P, C \u001b[38;5;241m=\u001b[39m get_ot_map(src_rep, mt_rep)\n\u001b[1;32m    413\u001b[0m predicted_align \u001b[38;5;241m=\u001b[39m get_predicted_alignment(P, method\u001b[38;5;241m=\u001b[39mmethod, thres\u001b[38;5;241m=\u001b[39mthres, is_fwd\u001b[38;5;241m=\u001b[39mis_fwd)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1363\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:662\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1087\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1078\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:297\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:1976\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   1973\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   1975\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[0;32m-> 1976\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1978\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   1981\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2011\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_mpl_hook()\n\u001b[1;32m   2010\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2011\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2013\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2015\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Analyze the hallucination labels\n",
    "import matplotlib.pyplot as plt\n",
    "from OTAlign.src.model_parts import *\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import ot\n",
    "from tqdm import tqdm\n",
    "def pmi_align(src_rep, mt_rep):\n",
    "    src_rep = torch.stack(src_rep, dim=0).cuda()\n",
    "    mt_rep = torch.stack(mt_rep, dim=0).cuda()\n",
    "    \n",
    "    def pmi_matrix(out_src, out_tgt):\n",
    "        out_src.div_(torch.norm(out_src, dim=-1).unsqueeze(-1))\n",
    "        out_tgt.div_(torch.norm(out_tgt, dim=-1).unsqueeze(-1))\n",
    "            \n",
    "        sim = torch.matmul(out_src, out_tgt.transpose(-1, -2))\n",
    "        sim = torch.softmax(sim.view(-1), dim=0).view(sim.size())\n",
    "        \n",
    "        probs_src = torch.sum(sim, dim = 1)\n",
    "        probs_tgt = torch.sum(sim, dim = 0)\n",
    "        \n",
    "        repeat_probs_src = probs_src.unsqueeze(1).expand(-1, sim.size(-1))\n",
    "        repeat_probs_tgt = probs_tgt.repeat(sim.size(0), 1)\n",
    "        scores = torch.log(sim) - torch.log(repeat_probs_tgt) - torch.log(repeat_probs_src)\n",
    "        \n",
    "        scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    out_src = src_rep\n",
    "    out_tgt = mt_rep\n",
    "    \n",
    "    out_src.div_(torch.norm(out_src, dim=-1).unsqueeze(-1))\n",
    "    out_tgt.div_(torch.norm(out_tgt, dim=-1).unsqueeze(-1))\n",
    "\n",
    "    dot_prod = pmi_matrix(out_src, out_tgt)\n",
    "    \n",
    "    # A = iter_max(dot_prod.numpy())\n",
    "    # align_words = np.nonzero(A)\n",
    "    # align_words2 = set()\n",
    "    # for i in range(len(align_words[0])):\n",
    "    #   align_words2.add((sub2word_map_src[align_words[0][i]], sub2word_map_tgt[align_words[1][i]]))\n",
    "    \n",
    "\n",
    "    argmax_srctgt = torch.argmax(dot_prod, dim=-1)\n",
    "    argmax_tgtsrc = torch.argmax(dot_prod, dim=-2)\n",
    "\n",
    "    align_words_srctgt = set()\n",
    "    align_words_tgtsrc = set()\n",
    "    for i, j in enumerate(argmax_srctgt):\n",
    "        i = int(i) + 1\n",
    "        j = int(j) + 1\n",
    "        align_words_srctgt.add( (str(i), str(j))) \n",
    "    \n",
    "    for i, j in enumerate(argmax_tgtsrc):\n",
    "        i = int(i) + 1\n",
    "        j = int(j) + 1\n",
    "        align_words_tgtsrc.add( (str(j), str(i)) )\n",
    "    \n",
    "    align_words = align_words_srctgt.intersection(align_words_tgtsrc)\n",
    "    \n",
    "    # indices = sinkhorn(dot_prod)\n",
    "    # align_words = set()\n",
    "    # for p in indices:\n",
    "    #   align_words.add( (sub2word_map_src[p[0]], sub2word_map_tgt[p[1]]) )\n",
    "\n",
    "    alignStr = \"\"\n",
    "    for p in align_words:\n",
    "        alignStr += str(p[0]) + \"-\" + str(p[1]) + \" \"\n",
    "    \n",
    "    return alignStr        \n",
    "\n",
    "\n",
    "def map_original_to_tokenized(x1, x2):\n",
    "    mapping = {}\n",
    "    tokenized_index = 0\n",
    "    original_index = 0\n",
    "\n",
    "    while original_index < len(x2) and tokenized_index < len(x1):\n",
    "        original_word = x2[original_index]\n",
    "        subword_sequence = ''\n",
    "\n",
    "        indices = []\n",
    "        while tokenized_index < len(x1) and (subword_sequence != original_word):\n",
    "            subword = x1[tokenized_index].lstrip('##')\n",
    "            if subword_sequence + subword == original_word[:len(subword_sequence + subword)]:\n",
    "                subword_sequence += subword\n",
    "                indices.append(tokenized_index)\n",
    "                tokenized_index += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if not indices:\n",
    "            tokenized_index += 1\n",
    "        else:\n",
    "            mapping[original_index] = indices\n",
    "\n",
    "        original_index += 1\n",
    "\n",
    "    return mapping\n",
    "\n",
    "def map_original_to_sentencepiece(x1, x2):\n",
    "    mapping = {}\n",
    "    tokenized_index = 0\n",
    "    original_index = 0\n",
    "\n",
    "    # Replace with the actual underscore character used in your SentencePiece tokenization\n",
    "    sentence_piece_underscore = 'â–'\n",
    "\n",
    "    while original_index < len(x2) and tokenized_index < len(x1):\n",
    "        original_word = x2[original_index]\n",
    "        subword_sequence = ''\n",
    "\n",
    "        indices = []\n",
    "        while tokenized_index < len(x1) and (subword_sequence != original_word):\n",
    "            subword = x1[tokenized_index].lstrip(sentence_piece_underscore)\n",
    "            if subword and (subword_sequence + subword == original_word[:len(subword_sequence) + len(subword)]):\n",
    "                subword_sequence += subword\n",
    "                indices.append(tokenized_index)\n",
    "            tokenized_index += 1\n",
    "\n",
    "        # Special handling for tokens that are just the SentencePiece underscore or punctuation\n",
    "        if not indices and x1[tokenized_index - 1].strip(sentence_piece_underscore) == '':\n",
    "            indices.append(tokenized_index - 1)\n",
    "\n",
    "        if indices:\n",
    "            mapping[original_index] = indices\n",
    "\n",
    "        original_index += 1\n",
    "\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def get_word_embeddings(sentence, model, tokenizer):\n",
    "    # Tokenize the sentence and get corresponding IDs\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    # tokens = inputs.tokens()[1:-1]\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    mapping = map_original_to_tokenized(tokens, sentence.split())\n",
    "\n",
    "    # Get BERT embeddings for each token\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "    embeddings = outputs['hidden_states'][8].squeeze(0)[1:-1]\n",
    "\n",
    "    assert len(embeddings) == len(tokens)\n",
    "    \n",
    "    word_embeddings = []\n",
    "    for original_idx in range(len(sentence.split())):\n",
    "        subword_indices = mapping[original_idx]\n",
    "        subword_embeddings = [embeddings[idx] for idx in subword_indices]\n",
    "        averaged_embedding = torch.mean(torch.stack(subword_embeddings), dim=0)\n",
    "        word_embeddings.append(averaged_embedding)\n",
    "\n",
    "    assert len(word_embeddings) == len(sentence.split(\" \"))\n",
    "    return word_embeddings\n",
    "\n",
    "# word_level_emb = get_word_embeddings(\"This is an example sentence , which is meant to be encoded . Subwords are not a problem for this model .\", model, model.tokenizer)\n",
    "import torch\n",
    "\n",
    "def find_avg_vector_cosine_similarity(vectors, vectors2=None):\n",
    "    def cosine_distance(x, vectors):\n",
    "        # Normalize the vectors\n",
    "        x_norm = x / x.norm(dim=1, keepdim=True)\n",
    "        vectors_norm = vectors / vectors.norm(dim=1, keepdim=True)\n",
    "        # Compute cosine similarity and convert to distance\n",
    "        cosine_sim = torch.mm(vectors_norm, x_norm.t())\n",
    "        return 1 - cosine_sim\n",
    "\n",
    "    def objective_function_uniform_cosine(x, vectors):\n",
    "        distances = cosine_distance(x, vectors).squeeze()\n",
    "        return torch.var(distances)\n",
    "\n",
    "    def objective_function_sum_cosine(x, vectors):\n",
    "        distances = cosine_distance(x, vectors).squeeze()\n",
    "        return distances.mean()\n",
    "\n",
    "    def objective_function_sum_uniform_cosine(x, vectors):\n",
    "        distances = cosine_distance(x, vectors).squeeze()\n",
    "        return distances.mean() + torch.var(distances)\n",
    "\n",
    "    combined_vectors = torch.cat([vectors, vectors2], dim=0)\n",
    "    x = torch.mean(combined_vectors.detach(), dim=0, keepdim=True).clone().detach().requires_grad_(True)\n",
    "\n",
    "    optimizer = torch.optim.Adam([x], lr=0.01)\n",
    "    for _ in range(3000):  # Number of iterations\n",
    "        optimizer.zero_grad()\n",
    "        loss = objective_function_sum_uniform_cosine(x, combined_vectors.detach())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    optimizer = torch.optim.Adam([x], lr=0.01)\n",
    "    for _ in range(3000):  # Number of iterations\n",
    "        optimizer.zero_grad()\n",
    "        loss = objective_function_uniform_cosine(x, combined_vectors.detach())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return x.detach().squeeze(0)\n",
    "\n",
    "\n",
    "def find_avg_vector_cuda(vectors, vectors2=None):\n",
    "    def objective_function_uniform_l2(x, vectors, ):\n",
    "        distances = torch.norm(vectors - x, dim=1)\n",
    "        return torch.var(distances)\n",
    "        \n",
    "    def objective_function_sum_l2(x, vectors, ):\n",
    "        distances = torch.norm(vectors - x, dim=1)\n",
    "        return distances.mean()\n",
    "    \n",
    "    def objective_function_sum_uniform_l2(x, vectors, ):\n",
    "        distances = torch.norm(vectors - x, dim=1)\n",
    "        return distances.mean() + torch.var(distances)\n",
    "    \n",
    "    \n",
    "    combined_vectors = torch.cat([vectors, vectors2], dim=0)\n",
    "    x = torch.mean(combined_vectors.detach(), dim=0, keepdim=True).clone().detach().requires_grad_(True)\n",
    "    \n",
    "    optimizer = torch.optim.Adam([x], lr=0.01)\n",
    "    \n",
    "    over_all_loss = float('inf')\n",
    "    for _ in range(200):\n",
    "        previous_loss = float('inf')\n",
    "        for _ in range(3000):  # Number of iterations\n",
    "            optimizer.zero_grad()\n",
    "            loss = objective_function_sum_uniform_l2(x, combined_vectors.detach())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if torch.abs(previous_loss - loss) < 1e-6:\n",
    "                break\n",
    "            previous_loss = loss\n",
    "            \n",
    "        optimizer = torch.optim.Adam([x], lr=0.01)\n",
    "        previous_loss = float('inf')\n",
    "        for _ in range(3000):  # Number of iterations\n",
    "            optimizer.zero_grad()\n",
    "            loss = objective_function_uniform_l2(x, combined_vectors.detach())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if torch.abs(previous_loss - loss) < 1e-6:\n",
    "                break\n",
    "            previous_loss = loss\n",
    "\n",
    "        if torch.abs(over_all_loss - loss) < 1e-6:\n",
    "            break\n",
    "        over_all_loss = loss\n",
    "        \n",
    "    return x.detach().squeeze(0)\n",
    "\n",
    "def get_predicted_alignment(P, method='l2r', thres=None, is_fwd=False):\n",
    "    # Apply argmax along each row\n",
    "    null_idx = P.shape[1] - 1\n",
    "    if method == 'l2r':\n",
    "        alignment_indices = np.argmax(P, axis=1)\n",
    "        \n",
    "        # Generate alignment string\n",
    "        if is_fwd:\n",
    "            alignment_string = ' '.join(f'{i+1}-{j+1}' for i, j in enumerate(alignment_indices) if j != null_idx and sum(P[i]) > 0)\n",
    "        else:\n",
    "            alignment_string = ' '.join(f'{j+1}-{i+1}' for i, j in enumerate(alignment_indices) if j != null_idx and sum(P[i]) > 0)\n",
    "        \n",
    "    elif method == 'r2f':\n",
    "        alignment_indices = np.argmax(P, axis=0)\n",
    "        # Generate alignment string\n",
    "        if is_fwd:\n",
    "            alignment_string = ' '.join(f'{j+1}-{i+1}' for i, j in enumerate(alignment_indices) if j != null_idx and sum(P[:, i]) > 0)\n",
    "        else:\n",
    "            alignment_string = ' '.join(f'{i+1}-{j+1}' for i, j in enumerate(alignment_indices) if j != null_idx and sum(P[:, i]) > 0)\n",
    "        \n",
    "    elif method == 'thres':\n",
    "        assert thres is not None\n",
    "        P_thres = P.copy()\n",
    "        thres = P_thres[:, :-1].sum(axis=1)[:, np.newaxis] * thres  # can be designed\n",
    "        bin_P = (P_thres >= thres).astype(int)\n",
    "        alignments = []\n",
    "        # Iterate over the matrix\n",
    "        for i in range(bin_P.shape[0]):  # For each source (row)\n",
    "            if P_thres[i].argmax(-1) == null_idx:\n",
    "                continue\n",
    "            for j in range(bin_P.shape[1]):  # For each target (column)\n",
    "                if j == null_idx:\n",
    "                    continue\n",
    "                if bin_P[i, j] == 1:\n",
    "                    # Record the alignment, adjusting index to be one-based\n",
    "                    if is_fwd:\n",
    "                        alignments.append(f\"{i+1}-{j+1}\")\n",
    "                    else:\n",
    "                        alignments.append(f\"{j+1}-{i+1}\")\n",
    "        # Join all alignments into a string\n",
    "        alignment_string = ' '.join(alignments)\n",
    "    \n",
    "    return alignment_string\n",
    "\n",
    "def get_join_alignments(fwd_align, rev_align, method='union'):\n",
    "    fwd_align_pairs = rank_align_pairs(fwd_align)\n",
    "    rev_align_pairs = rank_align_pairs(rev_align)\n",
    "    \n",
    "    if method == 'union':\n",
    "        align_pairs = list(set(fwd_align_pairs).union(set(rev_align_pairs)))\n",
    "    elif method == 'intersection':\n",
    "        align_pairs = list(set(fwd_align_pairs).intersection(set(rev_align_pairs)))\n",
    "    elif method == '':\n",
    "        align_pairs = list(set(fwd_align_pairs).symmetric_difference(set(rev_align_pairs)))\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    align_pairs = sorted(align_pairs, key=lambda x: x[0])\n",
    "    align_string = ' '.join([f'{pair[0]}-{pair[1]}' for pair in align_pairs])\n",
    "    return align_string\n",
    "    \n",
    "    \n",
    "def rank_align_pairs(align):\n",
    "    align_pairs = align.split()\n",
    "    align_pairs = [pair.split('-') for pair in align_pairs if 'p' not in pair]\n",
    "    align_pairs = [(int(pair[0]), int(pair[1])) for pair in align_pairs]\n",
    "    align_pairs = sorted(align_pairs, key=lambda x: x[0] * 1000 + x[1])\n",
    "    return align_pairs\n",
    "\n",
    "m = 0.5\n",
    "epsilon = 0.1\n",
    "numItermax = 3000\n",
    "stopThr = 1e-8\n",
    "\n",
    "def get_ot_align(src_rep, mt_rep, simple_avg_unk=False, method='l2r',  thres=0.3, is_fwd=False):\n",
    "    def get_ot_map(src_rep, mt_rep, m=m, epsilon=epsilon, numItermax=numItermax, stopThr=stopThr, w1=None, w2=None):\n",
    "        def convert_to_numpy(s1_weights, s2_weights, C):\n",
    "            if torch.is_tensor(s1_weights):\n",
    "                s1_weights = s1_weights.to('cpu').numpy()\n",
    "                s2_weights = s2_weights.to('cpu').numpy()\n",
    "            if torch.is_tensor(C):\n",
    "                C = C.to('cpu').numpy()\n",
    "            return s1_weights, s2_weights, C\n",
    "        \n",
    "        # src_rep = src_rep.copy()\n",
    "        # mt_rep = mt_rep.copy()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # C = 1 - pmi_matrix(mt_rep, src_rep).cpu()\n",
    "\n",
    "        # return 1 - C, C\n",
    "        \n",
    "        C = compute_distance_matrix_l2(mt_rep, src_rep, 0.0) # len(mt_rep) x len(src_rep)\n",
    "        # C = compute_distance_matrix_cosine(mt_rep, src_rep, 0.0)\n",
    "        \n",
    "        \n",
    "        if simple_avg_unk:\n",
    "            def get_equal_n_min_dist(ser_rep, ref_rep):\n",
    "                x = torch.cat([ser_rep, ref_rep], dim=0)\n",
    "                b = (x.norm(dim=1)[0].unsqueeze(0) ** 2 - x.norm(dim=1)[1:] ** 2) / 2\n",
    "                A = x[0].unsqueeze(0) - x[1:]\n",
    "                A_pinv = A.pinverse()\n",
    "                d = (A_pinv @ ( A @ x[0] - b)).norm()\n",
    "                return d\n",
    "                # # d = (A_pinv @ ( A @ x[0].unsqueeze(1) - b)).norm()\n",
    "                \n",
    "                # d = (x[0] - A_pinv @ b).norm()\n",
    "                # f = (x[0] - A_pinv @ b)\n",
    "                \n",
    "                # d = A_pinv @ A @ x[0] - A_pinv @ A @ A_pinv @ b\n",
    "                # A_pinv @ A @ x[0] - A_pinv @ b\n",
    "                # (A_pinv @ ( A @ x[0] - b )).norm()\n",
    "                # # d = (f - (torch.eye(f.shape[0]) - A_pinv @ A ) @ f).norm()\n",
    "                # d = (A_pinv @ A @ f).norm()\n",
    "                # return d\n",
    "\n",
    "\n",
    "            avg_C = C.mean()\n",
    "            C = torch.cat([C, torch.ones(C.shape[0], 1).to(C) * avg_C], dim=1)\n",
    "        \n",
    "        #  NOTE: s1 correspoins to mt\n",
    "        #  NOTE: s2 correspoins to src\n",
    "        \n",
    "        s1_weights, s2_weights = compute_weights_uniform(mt_rep, src_rep)\n",
    "        # s1_weights, s2_weights = compute_weights_norm(mt_rep, src_rep)\n",
    "        \n",
    "        s1_weights = s1_weights / s1_weights.sum() \n",
    "        s1_weights *= 1.5\n",
    "        \n",
    "        if simple_avg_unk:\n",
    "            s2_weights = torch.cat([s2_weights, torch.tensor([1.0]).to(C)], dim=0)   \n",
    "\n",
    "        s2_weights[-1] = 0.0\n",
    "        s2_weights = s2_weights / s2_weights.sum()\n",
    "        # s2_weights *= 1.5\n",
    "        \n",
    "        # s2_weights[:-1].sum() * 0.5\n",
    "        s1_weights, s2_weights, C = convert_to_numpy(s1_weights, s2_weights, C)\n",
    "        # m = np.min((np.sum(s1_weights), np.sum(s2_weights))) * m\n",
    "        # m = s2_weights.sum() / (s1_weights.sum() + s2_weights.sum())\n",
    "        \n",
    "        m = 0.9999\n",
    "        # P = ot.partial.entropic_partial_wasserstein(s1_weights, s2_weights, C, reg=epsilon, m=m, stopThr=stopThr, numItermax=numItermax)\n",
    "        \n",
    "        P = ot.sinkhorn(s1_weights, s2_weights, C, epsilon, numItermax=numItermax)\n",
    "        # P = ot.emd(s1_weights, s2_weights, C)\n",
    "        # P = min_max_scaling(P)\n",
    "        # P = ot.unbalanced.sinkhorn_stabilized_unbalanced(s1_weights, s2_weights, C, reg=epsilon, reg_m=(0.1, 0.1), stopThr=stopThr, numItermax=numItermax)\n",
    "        # P = min_max_scaling(P)\n",
    "        \n",
    "        # P = ot.emd(s1_weights / s1_weights.sum(), s2_weights / s2_weights.sum(), C)\n",
    "        # tmp = 0\n",
    "        \n",
    "        return P, C\n",
    "    \n",
    "    src_rep = torch.stack(src_rep, dim=0).cuda()\n",
    "    mt_rep = torch.stack(mt_rep, dim=0).cuda()\n",
    "\n",
    "    \n",
    "    if not simple_avg_unk:\n",
    "        # avg_src_rep = find_avg_vector_cosine_similarity(src_rep, mt_rep)\n",
    "        avg_src_rep = find_avg_vector_cuda(src_rep, mt_rep).detach()\n",
    "        # avg_src_rep = find_avg_vector_xy(src_rep, mt_rep).detach()\n",
    "        avg_src_rep = avg_src_rep.to(mt_rep)\n",
    "        src_rep = torch.cat([src_rep, avg_src_rep.unsqueeze(0)], dim=0)\n",
    "        \n",
    "    P, C = get_ot_map(src_rep, mt_rep)\n",
    "    \n",
    "    predicted_align = get_predicted_alignment(P, method=method, thres=thres, is_fwd=is_fwd)\n",
    "    return predicted_align, P, C\n",
    "\n",
    "\n",
    "\n",
    "src = 'de'\n",
    "tgt = 'en'\n",
    "num_samples = len(open(f'PMI-Align/data/{src}-{tgt}/text.{src}', 'r').readlines())\n",
    "\n",
    "\n",
    "results = []\n",
    "results_fwd = []\n",
    "results_rev = []\n",
    "results_union = []\n",
    "results_intersection = []\n",
    "results_soft_inter = []\n",
    "\n",
    "gold_aligen_list = []\n",
    "\n",
    "with tqdm(total=num_samples, desc='Processing') as pbar:\n",
    "# if True:\n",
    "#     test_line_id = 508\n",
    "    for test_line_id in range(num_samples):\n",
    "        # gold_alignment = open('data/deen/alignmentDeEn.talp', 'r').readlines()[test_line_id]\n",
    "        # src_text = open('data/deen/de', 'r', encoding='latin-1').readlines()[test_line_id].strip()\n",
    "        # tgt_text = open('data/deen/en', 'r', encoding='latin-1').readlines()[test_line_id].strip()\n",
    "        \n",
    "        \n",
    "\n",
    "        gold_alignment = open(f'PMI-Align/data/{src}-{tgt}/gold.{src}-{tgt}.aligned', 'r').readlines()[test_line_id]\n",
    "        src_text = open(f'PMI-Align/data/{src}-{tgt}/text.{src}', 'r').readlines()[test_line_id].strip()\n",
    "        tgt_text = open(f'PMI-Align/data/{src}-{tgt}/text.{tgt}', 'r',).readlines()[test_line_id].strip()\n",
    "        \n",
    "        if len(src_text.split()) == 0:\n",
    "            print('Finished @', test_line_id)\n",
    "            print('Processed', len(results), 'samples')\n",
    "            break\n",
    "        # print(src_text)\n",
    "        # print(tgt_text)\n",
    "        \n",
    "        try:\n",
    "            src_emb_ = get_word_embeddings(src_text, model, tokenizer)\n",
    "            tgt_emb_ = get_word_embeddings(tgt_text, model, tokenizer)\n",
    "        except Exception as e:\n",
    "            print('error emb @', test_line_id)\n",
    "            continue\n",
    "        \n",
    "        predicted_alin_rev, P_rev, C_rev = get_ot_align(src_emb_, tgt_emb_, simple_avg_unk=False, method='l2r', thres=0.2, is_fwd=False)\n",
    "        \n",
    "        predicted_alin_fwd, P_fwd, C_fwd = get_ot_align(tgt_emb_, src_emb_, simple_avg_unk=True, method='l2r', thres=0.2, is_fwd=True)\n",
    "        \n",
    "        pmi_align_str = pmi_align(src_emb_, tgt_emb_)\n",
    "\n",
    "        union_align = get_join_alignments(predicted_alin_fwd, predicted_alin_rev, method='union')\n",
    "        inter_align = get_join_alignments(predicted_alin_fwd, predicted_alin_rev, method='intersection')\n",
    "        \n",
    "        P_rev[:, :-1] + P_fwd.T[:-1, :]\n",
    "        \n",
    "        P_copy = P_rev.copy()\n",
    "        P_copy[:, :-1] = (P_rev[:, :-1] + P_fwd.T[:-1, :]) / 2\n",
    "        soft_rev = get_predicted_alignment(P_copy, method='l2r', thres=0.1, is_fwd=False)\n",
    "        \n",
    "        P_copy = P_fwd.copy()\n",
    "        P_copy[:, :-1] = (P_rev.T[:-1,:] + P_fwd[:, :-1]) / 2\n",
    "        soft_fwd = get_predicted_alignment(P_copy, method='l2r', thres=0.1, is_fwd=True)\n",
    "        \n",
    "        soft_inter_aligns = get_join_alignments(soft_fwd, soft_rev, method='intersection')\n",
    "        \n",
    "        # try:\n",
    "        #     f1_aer = evaluate_sent_level(inter_align, gold_alignment.strip())\n",
    "        #     f1_aer_fwd = evaluate_sent_level(predicted_alin_fwd, gold_alignment.strip())\n",
    "        #     f1_aer_rev = evaluate_sent_level(predicted_alin_rev, gold_alignment.strip())\n",
    "        #     f1_aer_union = evaluate_sent_level(union_align, gold_alignment.strip())\n",
    "        #     f1_aer_intersection = evaluate_sent_level(inter_align, gold_alignment.strip())\n",
    "            \n",
    "        # except Exception as e:\n",
    "        #     print('all null @', test_line_id)\n",
    "        #     # f1_aer = {\"F1 Score\": 0, \"AER\": 1, \"Precision\": 0, \"Recall\": 0}\n",
    "        #     continue\n",
    "        \n",
    "        gold_aligen_list.append(gold_alignment.strip())\n",
    "        results.append(pmi_align_str)\n",
    "        results_fwd.append(predicted_alin_fwd)\n",
    "        results_rev.append(predicted_alin_rev)\n",
    "        results_union.append(union_align)\n",
    "        results_intersection.append(inter_align)\n",
    "        results_soft_inter.append(soft_inter_aligns)\n",
    "        \n",
    "        eval_result = evaluate_corpus_level(results_intersection, gold_aligen_list)\n",
    "        f1 = eval_result['F1 Score']\n",
    "        aer = eval_result['AER']\n",
    "        precision = eval_result['Precision']\n",
    "        recall = eval_result['Recall']\n",
    "        \n",
    "        avg_f1_str = f'{f1:.4f}'\n",
    "        avg_aer_str = f'{aer:.4f}'\n",
    "        avg_pre_str = f'{precision:.4f}'\n",
    "        avg_rec_str = f'{recall:.4f}'\n",
    "        \n",
    "        pbar.set_postfix({'F1': avg_f1_str, 'AER': avg_aer_str, 'Precision': avg_pre_str, 'Recall': avg_rec_str})\n",
    "        pbar.update(1)\n",
    "\n",
    "        # f'Average Precision: {np.mean([result[\"Precision\"] for result in results]):.4f}, Average Recall: {np.mean([result[\"Recall\"] for result in results]):.4f}, Average F1 Score: {np.mean([result[\"F1 Score\"] for result in results]):.4f}, Average AER: {np.mean([result[\"AER\"] for result in results]):.4f}'\n",
    "        \n",
    "        DEBUG = True\n",
    "        if DEBUG:\n",
    "            x = src_text.split()\n",
    "            x_null = x + ['NULL']\n",
    "            \n",
    "            y = tgt_text.split()\n",
    "            y_null = y + ['NULL']\n",
    "            \n",
    "            fig_width = max(16, len(x))  # Doubling the width to accommodate both heatmaps\n",
    "            fig_height = max(6, len(y) * 0.5)  # 0.5 inch per row\n",
    "            \n",
    "            plt.figure(figsize=(fig_width, fig_height))\n",
    "            # tres = P_copy.sum(0).mean() * 0.0\n",
    "            # P_copy[P_copy<tres] = 0\n",
    "        \n",
    "            # Heatmap for P\n",
    "            plt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot\n",
    "            plt.imshow(P_fwd.T, cmap='hot', interpolation='nearest')\n",
    "            plt.colorbar()\n",
    "            plt.xticks(ticks=np.arange(len(x)), labels=x, rotation=90)\n",
    "            plt.yticks(ticks=np.arange(len(y_null)), labels=y_null)\n",
    "            plt.title(\"Heatmap of P_Fwd\")\n",
    "            plt.grid(which='major', axis='both', linestyle='-', color='white', linewidth=0.5)\n",
    "            plt.gca().set_xticks(np.arange(-0.5, len(x), 1), minor=True)\n",
    "            plt.gca().set_yticks(np.arange(-0.5, len(y_null), 1), minor=True)\n",
    "\n",
    "            # Heatmap for C\n",
    "            plt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot\n",
    "            plt.imshow(P_rev, cmap='hot', interpolation='nearest')\n",
    "            plt.colorbar()\n",
    "            plt.xticks(ticks=np.arange(len(x_null)), labels=x_null, rotation=90)\n",
    "            plt.yticks(ticks=np.arange(len(y)), labels=y)\n",
    "            plt.title(\"Heatmap of P_rev\")\n",
    "            plt.grid(which='major', axis='both', linestyle='-', color='white', linewidth=0.5)\n",
    "            plt.gca().set_xticks(np.arange(-0.5, len(x_null), 1), minor=True)\n",
    "            plt.gca().set_yticks(np.arange(-0.5, len(y), 1), minor=True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            # fig.canvas.draw()\n",
    "            plt.show()\n",
    "            print(rank_align_pairs(gold_alignment))\n",
    "            print(rank_align_pairs(inter_align))\n",
    "                        \n",
    "            print(rank_align_pairs(predicted_alin_fwd))\n",
    "            print(rank_align_pairs(predicted_alin_rev))\n",
    "            \n",
    "            print(evaluate_sent_level(predicted_alin_fwd, gold_alignment.strip()))\n",
    "            print(evaluate_sent_level(predicted_alin_rev, gold_alignment.strip()))\n",
    "            \n",
    "            \n",
    "            tmp = 0\n",
    "\n",
    "    \n",
    "    \n",
    "    result = evaluate_corpus_level(results, gold_aligen_list)\n",
    "    print(\"Average F1 Score:\", result['F1 Score'])\n",
    "    print(\"Average AER:\", result['AER'])\n",
    "    print(\"Average Precision:\", result['Precision'])\n",
    "    print(\"Average Recall:\", result['Recall'])\n",
    "\n",
    "    print()\n",
    "    result_fwd = evaluate_corpus_level(results_fwd, gold_aligen_list)\n",
    "    print(\"Average F1 Score Fwd:\", result_fwd['F1 Score'])\n",
    "    print(\"Average AER Fwd:\", result_fwd['AER'])\n",
    "    print(\"Average Precision Fwd:\", result_fwd['Precision'])\n",
    "    print(\"Average Recall Fwd:\", result_fwd['Recall'])\n",
    "\n",
    "    print()\n",
    "    result_rev = evaluate_corpus_level(results_rev, gold_aligen_list)\n",
    "    print(\"Average F1 Score Rev:\", result_rev['F1 Score'])\n",
    "    print(\"Average AER Rev:\", result_rev['AER'])\n",
    "    print(\"Average Precision Rev:\", result_rev['Precision'])\n",
    "    print(\"Average Recall Rev:\", result_rev['Recall'])\n",
    "\n",
    "    print()\n",
    "    result_union = evaluate_corpus_level(results_union, gold_aligen_list)\n",
    "    print(\"Average F1 Score Union:\", result_union['F1 Score'])\n",
    "    print(\"Average AER Union:\", result_union['AER'])\n",
    "    print(\"Average Precision Union:\", result_union['Precision'])\n",
    "    print(\"Average Recall Union:\", result_union['Recall'])\n",
    "\n",
    "    print()\n",
    "    result_intersection = evaluate_corpus_level(results_intersection, gold_aligen_list)\n",
    "    print(\"Average F1 Score Intersection:\", result_intersection['F1 Score'])\n",
    "    print(\"Average AER Intersection:\", result_intersection['AER'])\n",
    "    print(\"Average Precision Intersection:\", result_intersection['Precision'])\n",
    "    print(\"Average Recall Intersection:\", result_intersection['Recall'])\n",
    "\n",
    "    print()\n",
    "    result_soft_inter = evaluate_corpus_level(results_soft_inter, gold_aligen_list)\n",
    "    print(\"Average F1 Score Soft Intersection:\", result_soft_inter['F1 Score'])\n",
    "    print(\"Average AER Soft Intersection:\", result_soft_inter['AER'])\n",
    "    print(\"Average Precision Soft Intersection:\", result_soft_inter['Precision'])\n",
    "    print(\"Average Recall Soft Intersection:\", result_soft_inter['Recall'])\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.9401214660975792\n",
      "Average AER: 0.0572804590634286\n",
      "Average Precision: 0.9542038105226359\n",
      "Average Recall: 0.9264487369985142\n",
      "\n",
      "Average F1 Score Fwd: 0.9289114531277483\n",
      "Average AER Fwd: 0.07635626784562954\n",
      "Average Precision Fwd: 0.9067311922569292\n",
      "Average Recall Fwd: 0.9522040614165428\n",
      "\n",
      "Average F1 Score Rev: 0.9248643000583555\n",
      "Average AER Rev: 0.08430851063829792\n",
      "Average Precision Rev: 0.8887047776857222\n",
      "Average Recall Rev: 0.9640911342248638\n",
      "\n",
      "Average F1 Score Union: 0.9164590466800787\n",
      "Average AER Union: 0.10002455594663173\n",
      "Average Precision Union: 0.8601296001956229\n",
      "Average Recall Union: 0.9806835066864784\n",
      "\n",
      "Average F1 Score Intersection: 0.9424243542405752\n",
      "Average AER Intersection: 0.05625000000000002\n",
      "Average Precision Intersection: 0.949336960217613\n",
      "Average Recall Intersection: 0.9356116889549282\n",
      "\n",
      "Average F1 Score Soft Intersection: 0.9437570750969195\n",
      "Average AER Soft Intersection: 0.053709229344582776\n",
      "Average Precision Soft Intersection: 0.9577539165639852\n",
      "Average Recall Soft Intersection: 0.9301634472511144\n"
     ]
    }
   ],
   "source": [
    "result = evaluate_corpus_level(results, gold_aligen_list)\n",
    "print(\"Average F1 Score:\", result['F1 Score'])\n",
    "print(\"Average AER:\", result['AER'])\n",
    "print(\"Average Precision:\", result['Precision'])\n",
    "print(\"Average Recall:\", result['Recall'])\n",
    "\n",
    "print()\n",
    "result_fwd = evaluate_corpus_level(results_fwd, gold_aligen_list)\n",
    "print(\"Average F1 Score Fwd:\", result_fwd['F1 Score'])\n",
    "print(\"Average AER Fwd:\", result_fwd['AER'])\n",
    "print(\"Average Precision Fwd:\", result_fwd['Precision'])\n",
    "print(\"Average Recall Fwd:\", result_fwd['Recall'])\n",
    "\n",
    "print()\n",
    "result_rev = evaluate_corpus_level(results_rev, gold_aligen_list)\n",
    "print(\"Average F1 Score Rev:\", result_rev['F1 Score'])\n",
    "print(\"Average AER Rev:\", result_rev['AER'])\n",
    "print(\"Average Precision Rev:\", result_rev['Precision'])\n",
    "print(\"Average Recall Rev:\", result_rev['Recall'])\n",
    "\n",
    "print()\n",
    "result_union = evaluate_corpus_level(results_union, gold_aligen_list)\n",
    "print(\"Average F1 Score Union:\", result_union['F1 Score'])\n",
    "print(\"Average AER Union:\", result_union['AER'])\n",
    "print(\"Average Precision Union:\", result_union['Precision'])\n",
    "print(\"Average Recall Union:\", result_union['Recall'])\n",
    "\n",
    "print()\n",
    "result_intersection = evaluate_corpus_level(results_intersection, gold_aligen_list)\n",
    "print(\"Average F1 Score Intersection:\", result_intersection['F1 Score'])\n",
    "print(\"Average AER Intersection:\", result_intersection['AER'])\n",
    "print(\"Average Precision Intersection:\", result_intersection['Precision'])\n",
    "print(\"Average Recall Intersection:\", result_intersection['Recall'])\n",
    "\n",
    "print()\n",
    "result_soft_inter = evaluate_corpus_level(results_soft_inter, gold_aligen_list)\n",
    "print(\"Average F1 Score Soft Intersection:\", result_soft_inter['F1 Score'])\n",
    "print(\"Average AER Soft Intersection:\", result_soft_inter['AER'])\n",
    "print(\"Average Precision Soft Intersection:\", result_soft_inter['Precision'])\n",
    "print(\"Average Recall Soft Intersection:\", result_soft_inter['Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(13, 13), (14, 13), (15, 14), (16, 8), (17, 10), (17, 9), (17, 12), (17, 11), (18, 15)]\n",
      "[(3, 1), (4, 4), (5, 10), (6, 7), (7, 9), (8, 2), (9, 8), (10, 6), (11, 5), (12, 12), (13, 13), (15, 14), (17, 11), (18, 15)]\n",
      "F1 Score: 0.34782608695652173\n",
      "AER: 0.5652173913043479\n"
     ]
    }
   ],
   "source": [
    "def get_predicted_alignment(P):\n",
    "    # Apply argmax along each row\n",
    "    alignment_indices = np.argmax(P, axis=1)\n",
    "    null_idx = P.shape[1] - 1\n",
    "    # Generate alignment string\n",
    "    alignment_string = ' '.join(f'{j+1}-{i+1}' for i, j in enumerate(alignment_indices) if j != null_idx and sum(P[i]) > 0)\n",
    "    return alignment_string\n",
    "\n",
    "def rank_align_pairs(align):\n",
    "    align_pairs = align.split()\n",
    "    align_pairs = [pair.split('-') for pair in align_pairs if 'p' not in pair]\n",
    "    align_pairs = [(int(pair[0]), int(pair[1])) for pair in align_pairs]\n",
    "    align_pairs = sorted(align_pairs, key=lambda x: x[0])\n",
    "    return align_pairs\n",
    "\n",
    "null_idx = P.shape[1] - 1\n",
    "# clone numpy array P\n",
    "threshod = 1 / P.shape[1] * 0.5\n",
    "P_copy = P.copy()\n",
    "P_copy[P_copy<threshod] = 0\n",
    "\n",
    "# P_copy[P_copy<0.0001] = null_idx\n",
    "predicted_align = get_predicted_alignment(P_copy)\n",
    "print(rank_align_pairs(gold_alignment))\n",
    "print(rank_align_pairs(predicted_align))\n",
    "evaluate(predicted_align, gold_alignment.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0], 1: [1], 2: [2], 3: [4], 4: [5], 5: [6], 6: [7], 7: [8, 9], 8: [10, 11, 12], 9: [13], 10: [15]}\n"
     ]
    }
   ],
   "source": [
    "def map_original_to_sentencepiece(x1, x2):\n",
    "    mapping = {}\n",
    "    tokenized_index = 0\n",
    "    original_index = 0\n",
    "\n",
    "    # Replace with the actual underscore character used in your SentencePiece tokenization\n",
    "    sentence_piece_underscore = 'â–'\n",
    "\n",
    "    while original_index < len(x2) and tokenized_index < len(x1):\n",
    "        original_word = x2[original_index]\n",
    "        subword_sequence = ''\n",
    "\n",
    "        indices = []\n",
    "        while tokenized_index < len(x1) and (subword_sequence != original_word):\n",
    "            subword = x1[tokenized_index].lstrip(sentence_piece_underscore)\n",
    "            if subword and (subword_sequence + subword == original_word[:len(subword_sequence) + len(subword)]):\n",
    "                subword_sequence += subword\n",
    "                indices.append(tokenized_index)\n",
    "            tokenized_index += 1\n",
    "\n",
    "        # Special handling for tokens that are just the SentencePiece underscore or punctuation\n",
    "        if not indices and x1[tokenized_index - 1].strip(sentence_piece_underscore) == '':\n",
    "            indices.append(tokenized_index - 1)\n",
    "\n",
    "        if indices:\n",
    "            mapping[original_index] = indices\n",
    "\n",
    "        original_index += 1\n",
    "\n",
    "    return mapping\n",
    "\n",
    "# Example usage with SentencePiece tokenized and original sentences\n",
    "x1_sp = ['â–Wir', 'â–glauben', 'â–nicht', 'â–', ',', 'â–daÃŸ', 'â–wir', 'â–nur', 'â–Ros', 'inen', 'â–heraus', 'pi', 'cken', 'â–sollten', 'â–', '.']\n",
    "x2 = ['Wir', 'glauben', 'nicht', ',', 'daÃŸ', 'wir', 'nur', 'Rosinen', 'herauspicken', 'sollten', '.']\n",
    "mapping = map_original_to_sentencepiece(x1_sp, x2)\n",
    "print(mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 2), (2, 1), (0, 0)}\n"
     ]
    }
   ],
   "source": [
    "def parse_alignment_string(alignment_str):\n",
    "    return set(tuple(map(int, pair.split('-'))) for pair in alignment_str.split())\n",
    "\n",
    "def grow_diag_final(forward_str, reverse_str, src_len, tgt_len):\n",
    "    forward = parse_alignment_string(forward_str)\n",
    "    reverse = parse_alignment_string(reverse_str)\n",
    "\n",
    "    # Intersection\n",
    "    alignment = forward & reverse\n",
    "\n",
    "    # Define neighbors (8 surrounding points)\n",
    "    neighbors = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "\n",
    "    # Grow step\n",
    "    added = True\n",
    "    while added:\n",
    "        added = False\n",
    "        new_points = set()\n",
    "        for s, t in alignment:\n",
    "            for dx, dy in neighbors:\n",
    "                ns, nt = s + dx, t + dy\n",
    "                if 0 <= ns < src_len and 0 <= nt < tgt_len and (ns, nt) not in alignment:\n",
    "                    if (ns, nt) in forward or (ns, nt) in reverse:\n",
    "                        new_points.add((ns, nt))\n",
    "                        added = True\n",
    "        alignment.update(new_points)\n",
    "\n",
    "    # Final step\n",
    "    for s in range(src_len):\n",
    "        for t in range(tgt_len):\n",
    "            if all((s, t_) not in alignment for t_ in range(tgt_len)) and (s, t) in forward:\n",
    "                alignment.add((s, t))\n",
    "            if all((s_, t) not in alignment for s_ in range(src_len)) and (s, t) in reverse:\n",
    "                alignment.add((s, t))\n",
    "\n",
    "    return alignment\n",
    "\n",
    "# Example usage\n",
    "forward_str = '0-0 1-2'\n",
    "reverse_str = '0-0 2-1'\n",
    "src_len = 3  # Length of source sentence\n",
    "tgt_len = 3  # Length of target sentence\n",
    "\n",
    "result = grow_diag_final(forward_str, reverse_str, src_len, tgt_len)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 7 overall iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0300, 0.1346, 0.0642,  ..., 0.3329, 0.6323, 0.4940],\n",
       "        [0.0879, 0.1732, 0.2228,  ..., 0.8035, 0.7200, 0.7572],\n",
       "        [0.2075, 0.5142, 0.6605,  ..., 0.5421, 0.7076, 0.4122],\n",
       "        ...,\n",
       "        [0.1457, 0.0388, 0.0586,  ..., 0.5465, 0.8498, 0.3938],\n",
       "        [0.7954, 0.7071, 0.4792,  ..., 0.6445, 0.6863, 0.3283],\n",
       "        [0.0342, 0.4707, 0.0905,  ..., 0.5950, 0.4863, 0.9375]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming x and y are your data tensors\n",
    "# x: tensor of shape [m, dim]\n",
    "# y: tensor of shape [n, dim]\n",
    "def find_avg_vector2(x, y):\n",
    "    x = x.detach()\n",
    "    y = y.detach()\n",
    "    \n",
    "    def compute_l2_distance(tensor_a, tensor_b):\n",
    "        return torch.norm(tensor_a - tensor_b, dim=1)\n",
    "\n",
    "    def compute_pair_wise_l2_distance(tensor_a, tensor_b):\n",
    "        return torch.norm(tensor_a.unsqueeze(1) - tensor_b.unsqueeze(0), dim=2)\n",
    "    \n",
    "    def objective_initialization(c, x, y, alpha):\n",
    "        combined_x_y = torch.cat([x, y], dim=0)\n",
    "        xy_distances = compute_pair_wise_l2_distance(x, y)\n",
    "        c_to_xy_distances = compute_l2_distance(combined_x_y, c)\n",
    "        distance_diff = (xy_distances.view(-1).unsqueeze(1) - c_to_xy_distances.unsqueeze(0)).reshape(-1).abs().mean()\n",
    "        return alpha * c_to_xy_distances.mean() + (1 - alpha) * distance_diff\n",
    "\n",
    "    def variance_objective(c, x, y, lambda_weight):\n",
    "        combined_x_y = torch.cat([x, y], dim=0)\n",
    "        xy_distances = compute_pair_wise_l2_distance(x, y)\n",
    "        c_to_xy_distances = compute_l2_distance(combined_x_y, c)\n",
    "        var_c_to_xy = torch.var(c_to_xy_distances)\n",
    "        var_diff = (xy_distances.view(-1).unsqueeze(1) - c_to_xy_distances.unsqueeze(0)).reshape(-1).var()\n",
    "        return lambda_weight * var_c_to_xy + (1 - lambda_weight) * var_diff\n",
    "\n",
    "    # Parameters\n",
    "    alpha = 0.5\n",
    "    lambda_weight = 0.5\n",
    "    learning_rate = 0.01\n",
    "    max_iterations = 200\n",
    "    convergence_threshold = 1e-6\n",
    "\n",
    "    # Initialize c\n",
    "    c = torch.mean(torch.cat([x.detach(), y.detach()], dim=0), dim=0).requires_grad_(True).to(x)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam([c], lr=learning_rate)\n",
    "\n",
    "    # Iterative Process\n",
    "    previous_loss_all = float('inf')\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        # Step 1: Initialization Loop\n",
    "        previous_loss_median = float('inf')\n",
    "        for _idx in range(max_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            loss_init = objective_initialization(c, x, y, alpha)\n",
    "            loss_init.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Early Stopping for Step 1\n",
    "            if torch.abs(previous_loss_median - loss_init) < convergence_threshold:\n",
    "                break\n",
    "            previous_loss_median = loss_init\n",
    "\n",
    "        # Step 2: Variance Minimization Loop\n",
    "        previous_loss_var = float('inf')\n",
    "        for _idx in range(max_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            loss_variance = variance_objective(c, x, y, lambda_weight)\n",
    "            loss_variance.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Early Stopping for Step 2\n",
    "            if torch.abs(previous_loss_var - loss_variance) < convergence_threshold:\n",
    "                break\n",
    "            previous_loss_var = loss_variance\n",
    "\n",
    "        # Convergence Check for Overall Process\n",
    "        if torch.abs(loss_variance - previous_loss_all) < convergence_threshold:\n",
    "            print(f\"Converged in {iteration+1} overall iterations\")\n",
    "            break\n",
    "        previous_loss_all = loss_variance\n",
    "    # print(iteration)\n",
    "    return c\n",
    "    # print(f\"Final vector c: {c.detach().numpy()}\")\n",
    "\n",
    "# torch.manual_seed(11)  # For reproducibility\n",
    "x = torch.rand(15, 512)  # 5 x_i vectors\n",
    "y = torch.rand(20, 512)  # 3 y_i vectors\n",
    "\n",
    "c = find_avg_vector2(x, y)\n",
    "x.cuda()\n",
    "y.cuda()\n",
    "\n",
    "# print(x)\n",
    "# print(y)\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:04<00:06,  9.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mtotal_iterations, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_iterations):\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# Perform some operation\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Simulating a task\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m# Update the progress bar\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Total number of iterations\n",
    "total_iterations = 100\n",
    "\n",
    "# Initialize tqdm with the total parameter\n",
    "with tqdm(total=total_iterations, desc='Processing') as pbar:\n",
    "    for i in range(total_iterations):\n",
    "        # Perform some operation\n",
    "        time.sleep(0.1)  # Simulating a task\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Grow-diag-final output: {(0, 0), (2, 2)}\n"
     ]
    }
   ],
   "source": [
    "def grow_diag_final_balanced(forward_alignments, reverse_alignments, src_len, tgt_len):\n",
    "    \"\"\"\n",
    "    A more balanced implementation of Grow-diag-final heuristic.\n",
    "    \"\"\"\n",
    "    def get_neighbors(src, tgt):\n",
    "        \"\"\"Generate direct neighbors for a given source-target position.\"\"\"\n",
    "        neighbors = []\n",
    "        for d_src in [-1, 0, 1]:\n",
    "            for d_tgt in [-1, 0, 1]:\n",
    "                if d_src == 0 and d_tgt == 0:\n",
    "                    continue  # Skip the position itself\n",
    "                n_src, n_tgt = src + d_src, tgt + d_tgt\n",
    "                if 0 <= n_src < src_len and 0 <= n_tgt < tgt_len:\n",
    "                    neighbors.append((n_src, n_tgt))\n",
    "        return neighbors\n",
    "\n",
    "    # Step 1: Intersection as the starting point\n",
    "    combined_alignments = forward_alignments & reverse_alignments\n",
    "\n",
    "    # Step 2: Grow - selectively\n",
    "    unaligned_src = set(range(src_len))\n",
    "    unaligned_tgt = set(range(tgt_len))\n",
    "    for (src, tgt) in combined_alignments:\n",
    "        unaligned_src.discard(src)\n",
    "        unaligned_tgt.discard(tgt)\n",
    "\n",
    "    def is_neighbor_aligned(src, tgt):\n",
    "        for neighbor in get_neighbors(src, tgt):\n",
    "            if neighbor in combined_alignments:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    added = True\n",
    "    while added:\n",
    "        added = False\n",
    "        new_points = set()\n",
    "        for src in unaligned_src:\n",
    "            for tgt in unaligned_tgt:\n",
    "                if ((src, tgt) in forward_alignments or (src, tgt) in reverse_alignments) and is_neighbor_aligned(src, tgt):\n",
    "                    new_points.add((src, tgt))\n",
    "                    added = True\n",
    "\n",
    "        for point in new_points:\n",
    "            combined_alignments.add(point)\n",
    "            unaligned_src.discard(point[0])\n",
    "            unaligned_tgt.discard(point[1])\n",
    "\n",
    "    # Step 3: Final - cautiously add unique alignments without causing conflicts\n",
    "    for src in range(src_len):\n",
    "        for tgt in range(tgt_len):\n",
    "            if (src, tgt) in forward_alignments ^ reverse_alignments and not is_neighbor_aligned(src, tgt):\n",
    "                combined_alignments.add((src, tgt))\n",
    "\n",
    "    return combined_alignments\n",
    "\n",
    "# Example usage\n",
    "forward = {(0, 1), (2, 2), (1, 0)}\n",
    "reverse = {(0, 0), (2, 2), (1, 2)}\n",
    "src_length = 3\n",
    "tgt_length = 3\n",
    "\n",
    "combined = grow_diag_final_balanced(forward, reverse, src_length, tgt_length)\n",
    "print(\"Balanced Grow-diag-final output:\", combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_alignments(alignment_str, include_possible=False):\n",
    "    confirmed_src_to_tgt, confirmed_tgt_to_src = {}, {}\n",
    "    possible_src_to_tgt, possible_tgt_to_src = {}, {}\n",
    "\n",
    "    for pair in alignment_str.split():\n",
    "        if include_possible:\n",
    "            if 'p' in pair:  # Possible alignment\n",
    "                src, tgt = map(int, pair.split('p'))\n",
    "                possible_src_to_tgt.setdefault(src, []).append(tgt)\n",
    "                possible_tgt_to_src.setdefault(tgt, []).append(src)\n",
    "            else:  # Confirmed alignment\n",
    "                src, tgt = map(int, pair.split('-'))\n",
    "                possible_src_to_tgt.setdefault(src, []).append(tgt)\n",
    "                possible_tgt_to_src.setdefault(tgt, []).append(src)\n",
    "        else:\n",
    "            if 'p' in pair:  # Possible alignment\n",
    "                continue\n",
    "            else:\n",
    "                src, tgt = map(int, pair.split('-'))\n",
    "                confirmed_src_to_tgt.setdefault(src, []).append(tgt)\n",
    "                confirmed_tgt_to_src.setdefault(tgt, []).append(src)\n",
    "\n",
    "    if include_possible:\n",
    "        # combine confirmed_src_to_tgt and possible_src_to_tgt\n",
    "        return possible_src_to_tgt, possible_tgt_to_src\n",
    "    else:       \n",
    "        return confirmed_src_to_tgt, confirmed_tgt_to_src\n",
    "\n",
    "\n",
    "def calculate_sentence_ratios(src_to_tgt, tgt_to_src, total_src, total_tgt):\n",
    "    one_to_one = sum(len(tgt_list) == 1 for tgt_list in src_to_tgt.values())\n",
    "    src_one_to_many = sum(len(tgt_list) > 1 for tgt_list in src_to_tgt.values())\n",
    "    tgt_one_to_many = sum(len(src_list) > 1 for src_list in tgt_to_src.values())\n",
    "    \n",
    "    aligned_src = len(src_to_tgt)\n",
    "    aligned_tgt = len(tgt_to_src)\n",
    "    \n",
    "    missing_src_to_tgt = total_src - aligned_src\n",
    "    missing_tgt_to_src = total_tgt - aligned_tgt\n",
    "    \n",
    "    return {\n",
    "        \"one_to_one\": one_to_one,\n",
    "        \"missing_src_to_tgt\": missing_src_to_tgt,\n",
    "        \"missing_tgt_to_src\": missing_tgt_to_src,\n",
    "        \"src_one_to_many\": src_one_to_many,\n",
    "        \"tgt_one_to_many\": tgt_one_to_many,\n",
    "        \"total_src\": total_src,\n",
    "        \"total_tgt\": total_tgt,\n",
    "    }\n",
    "    \n",
    "\n",
    "def aggregate_corpus_metrics(sentence_metrics_list):\n",
    "    corpus_totals = {key: 0 for key in sentence_metrics_list[0]}\n",
    "    for metrics in sentence_metrics_list:\n",
    "        for key, value in metrics.items():\n",
    "            corpus_totals[key] += value\n",
    "        \n",
    "    # Correcting the denominator for one-to-one ratio calculation\n",
    "    total_alignments = sum((m[\"one_to_one\"] + m[\"src_one_to_many\"] + m[\"tgt_one_to_many\"]) for m in sentence_metrics_list)\n",
    "    if total_alignments == 0: total_alignments = 1  # Prevent division by zero\n",
    "    \n",
    "    _corpus_ratios = {\n",
    "        # The ratio of one-to-one alignments to the total number of alignments that have a counterpart in either direction\n",
    "        \"one_to_one_ratio\": corpus_totals['one_to_one'] / total_alignments,\n",
    "        \"missing_src_to_tgt_ratio\": corpus_totals[\"missing_src_to_tgt\"] / corpus_totals[\"total_src\"],\n",
    "        \"missing_tgt_to_src_ratio\": corpus_totals[\"missing_tgt_to_src\"] / corpus_totals[\"total_tgt\"],\n",
    "        \"src_to_tgt_one_to_many_ratio\": corpus_totals[\"src_one_to_many\"] / corpus_totals[\"total_src\"],\n",
    "        \"tgt_to_src_one_to_many_ratio\": corpus_totals[\"tgt_one_to_many\"] / corpus_totals[\"total_tgt\"],\n",
    "    }\n",
    "    return _corpus_ratios\n",
    "    \n",
    "def average_sentence_metrics(sentence_metrics_list):\n",
    "    \n",
    "    _sentence_level_metrics = {key: [] for key in sentence_metrics_list[0]}\n",
    "    for metrics in sentence_metrics_list:\n",
    "        if (metrics[\"one_to_one\"] + metrics[\"src_one_to_many\"] + metrics[\"tgt_one_to_many\"]) == 0:\n",
    "            continue\n",
    "        _sentence_level_metrics[\"one_to_one\"].append(metrics[\"one_to_one\"] / (metrics[\"one_to_one\"] + metrics[\"src_one_to_many\"] + metrics[\"tgt_one_to_many\"]))\n",
    "        _sentence_level_metrics[\"missing_src_to_tgt\"].append(metrics[\"missing_src_to_tgt\"] / metrics[\"total_src\"])\n",
    "        _sentence_level_metrics[\"missing_tgt_to_src\"].append(metrics[\"missing_tgt_to_src\"] / metrics[\"total_tgt\"])\n",
    "        _sentence_level_metrics[\"src_one_to_many\"].append(metrics[\"src_one_to_many\"] / metrics[\"total_src\"])\n",
    "        _sentence_level_metrics[\"tgt_one_to_many\"].append(metrics[\"tgt_one_to_many\"] / metrics[\"total_tgt\"])\n",
    "\n",
    "    # average sentence level metrics\n",
    "    _sentence_level_metrics = {key: np.mean(value) for key, value in _sentence_level_metrics.items()}\n",
    "            \n",
    "    return _sentence_level_metrics\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus-level Metrics:\n",
      "one_to_one_ratio: 0.62\n",
      "missing_src_to_tgt_ratio: 0.12\n",
      "missing_tgt_to_src_ratio: 0.08\n",
      "src_to_tgt_one_to_many_ratio: 0.21\n",
      "tgt_to_src_one_to_many_ratio: 0.21\n",
      "\n",
      "Sentence-level Averages:\n",
      "one_to_one: 0.64\n",
      "missing_src_to_tgt: 0.10\n",
      "missing_tgt_to_src: 0.07\n",
      "src_one_to_many: 0.22\n",
      "tgt_one_to_many: 0.22\n"
     ]
    }
   ],
   "source": [
    "src = 'en'\n",
    "tgt = 'fa'\n",
    "num_samples = len(open(f'PMI-Align/data/{src}-{tgt}/text.{src}', 'r').readlines())\n",
    "data_samples = []\n",
    "\n",
    "for test_line_id in range(num_samples):\n",
    "    # gold_alignment = open('data/deen/alignmentDeEn.talp', 'r').readlines()[test_line_id]\n",
    "    # src_text = open('data/deen/de', 'r', encoding='latin-1').readlines()[test_line_id].strip()\n",
    "    # tgt_text = open('data/deen/en', 'r', encoding='latin-1').readlines()[test_line_id].strip()\n",
    "    if len(src_text.split()) == 0:\n",
    "        print('Finished @', test_line_id)\n",
    "        print('Processed', len(results), 'samples')\n",
    "        break\n",
    "\n",
    "    gold_alignment = open(f'PMI-Align/data/{src}-{tgt}/gold.{src}-{tgt}.aligned', 'r').readlines()[test_line_id]\n",
    "    src_text = open(f'PMI-Align/data/{src}-{tgt}/text.{src}', 'r').readlines()[test_line_id].strip()\n",
    "    tgt_text = open(f'PMI-Align/data/{src}-{tgt}/text.{tgt}', 'r',).readlines()[test_line_id].strip()\n",
    "    data_samples.append((gold_alignment, len(src_text.split()), len(tgt_text.split())))\n",
    "        \n",
    "\n",
    "sentence_metrics_list = []\n",
    "for alignment_str, total_src, total_tgt in data_samples:\n",
    "    src_to_tgt, tgt_to_src = parse_alignments(alignment_str)\n",
    "    sentence_metrics = calculate_sentence_ratios(src_to_tgt, tgt_to_src, total_src, total_tgt)\n",
    "    sentence_metrics_list.append(sentence_metrics)\n",
    "\n",
    "corpus_ratios  = aggregate_corpus_metrics(sentence_metrics_list)\n",
    "\n",
    "sentence_ratios = average_sentence_metrics(sentence_metrics_list)\n",
    "\n",
    "print(\"Corpus-level Metrics:\")\n",
    "for key, value in corpus_ratios.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "\n",
    "print(\"\\nSentence-level Averages:\")\n",
    "for key, value in sentence_ratios.items():\n",
    "    if key not in [\"total_src\", \"total_tgt\"]:  # Skip total counts for average display\n",
    "        print(f\"{key}: {value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def read_alignment_metrics(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    data = {}\n",
    "    current_lang_pair = ''\n",
    "    current_section = None\n",
    "    for line in lines:\n",
    "        if len(line.strip()) != 5 and line.endswith('\\n'):\n",
    "            if 'Corpus-level Metrics:' not in line and 'Sentence-level Averages:' not in line:\n",
    "                key_value = line.strip().split(': ')\n",
    "                if len(key_value) == 2:\n",
    "                    key, value = key_value\n",
    "                    data[current_lang_pair][current_section][key] = float(value)\n",
    "            else:\n",
    "                if 'Corpus-level Metrics:' in line:\n",
    "                    current_section = 'Corpus-level Metrics'\n",
    "                elif 'Sentence-level Averages:' in line:\n",
    "                    current_section = 'Sentence-level Averages'\n",
    "                data[current_lang_pair][current_section] = {}\n",
    "        else:\n",
    "            current_lang_pair = line.strip()\n",
    "            data[current_lang_pair] = {}\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "file_path = 'PMI-Align/data/alignment_metrics.txt'\n",
    "data = read_alignment_metrics(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_grouped_bars_with_spacing(data):\n",
    "    # Adjusted order of metrics\n",
    "    metrics = ['one_to_one_ratio', 'src_to_tgt_one_to_many_ratio', 'tgt_to_src_one_to_many_ratio', 'missing_src_to_tgt_ratio', 'missing_tgt_to_src_ratio']\n",
    "    language_pairs = list(data.keys())\n",
    "\n",
    "    # Number of groups and bars in each group\n",
    "    n_groups = len(language_pairs)\n",
    "    n_bars = len(metrics)\n",
    "\n",
    "    # Create an array for the metric values for each language pair\n",
    "    values = np.array([[data[lang_pair]['Corpus-level Metrics'][metric] for metric in metrics] for lang_pair in language_pairs])\n",
    "\n",
    "    # Set up the figure and axes for the plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    # Set the positions of the bars and groups\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.15\n",
    "    opacity = 0.8\n",
    "    spacing = 0.03  # Additional spacing after the third bar\n",
    "\n",
    "    # Plotting each metric as a bar in each group\n",
    "    for i, metric in enumerate(metrics):\n",
    "        if i >= 3:  # Add spacing after the third metric\n",
    "            additional_space = spacing\n",
    "        else:\n",
    "            additional_space = 0\n",
    "        plt.bar(index + i*bar_width + additional_space, values[:, i], bar_width, alpha=opacity, label=metric)\n",
    "\n",
    "    plt.xlabel('Language Pair', fontsize=14)\n",
    "    plt.ylabel('Metric Value', fontsize=14)\n",
    "    plt.title('Metrics Comparison Across Language Pairs', fontsize=16)\n",
    "    plt.xticks(index + bar_width * (n_bars-1) / 2 + spacing/2, language_pairs, rotation=45)  # Adjust xticks to center them under groups\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_grouped_bars_with_spacing(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
